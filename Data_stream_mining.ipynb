{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data stream mining",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMuTHtwBjfuUOMvNaDVj1FV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacayz/Datastreammining/blob/main/Data_stream_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxqbGIAqVcj1"
      },
      "source": [
        "# **FARID SAHABI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKvEyqwg8U_",
        "outputId": "2106b0c0-d60b-4048-f155-01f0c0ee6d96"
      },
      "source": [
        "!pip install scikit-multiflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multiflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/b8/dc05e1232cb261429258da43dc6882b4da8debbb485f968f06426e0bf41a/scikit_multiflow-0.5.3-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 22.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 24.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 27.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 30.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 28.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 28.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 30.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 30.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112kB 30.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 30.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 30.2MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 30.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 30.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 604kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 686kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 716kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 747kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 798kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 829kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 849kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 880kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890kB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 931kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 962kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 993kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0MB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0MB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 30.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 30.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.4.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (2.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5iLecv-g4Hh"
      },
      "source": [
        "# Imports\n",
        "%matplotlib notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skmultiflow.data import SEAGenerator\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "import csv\n",
        "import pickle\n",
        "from skmultiflow.lazy import KNNClassifier\n",
        "from skmultiflow.meta import DynamicWeightedMajority\n",
        "from skmultiflow.meta import BatchIncrementalClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXSNCE-jhEbG"
      },
      "source": [
        "#setting up the first data stream\n",
        "stream = SEAGenerator(classification_function = 2, random_state = 20000, balance_classes = False, noise_percentage = 0)\n",
        "# Retrieving multiple sample and saving to a variable\n",
        "saved_batch = stream.next_sample(batch_size=20000)\n",
        "with open('SEA Dataset', 'wb') as file:\n",
        "    pickle.dump(saved_batch, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Mai0kE3cxB"
      },
      "source": [
        "#setting up the second data stream\n",
        "stream2 = SEAGenerator(classification_function = 2, random_state = 20000, balance_classes = False, noise_percentage = 0.1)\n",
        "# Retrieving multiple sample\n",
        "saved_batch2 = stream2.next_sample(20000)\n",
        "with open('SEA Dataset10', 'wb') as file:\n",
        "    pickle.dump(saved_batch2, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzWBNo_m32Zo"
      },
      "source": [
        "#setting up the third data stream\n",
        "stream3 = SEAGenerator(classification_function = 2, random_state = 20000, balance_classes = False, noise_percentage = 0.7)\n",
        "# Retrieving multiple sample\n",
        "saved_batch3 = stream3.next_sample(20000)\n",
        "with open('SEA Dataset70', 'wb') as file:\n",
        "    pickle.dump(saved_batch3, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TQtowMED_8v"
      },
      "source": [
        "## **HT** on first data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0KqSiT4B5w"
      },
      "source": [
        "# Setup Hoeffding Tree estimator and making prediction  - \n",
        "ht = HoeffdingTreeClassifier()\n",
        "# Setup variables to control loop and track performance\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "max_samples = 20000\n",
        "\n",
        "# Train the estimator with the samples provided by the data stream\n",
        "while n_samples < max_samples and stream.has_more_samples():\n",
        "    X, y = stream.next_sample()\n",
        "    y_pred = ht.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    ht = ht.partial_fit(X, y)\n",
        "    n_samples += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a8RBHTV-eKG",
        "outputId": "4df5a0fd-1d78-4a1e-d1b0-1b867eb2e71a"
      },
      "source": [
        "print('{} samples analyzed.'.format(n_samples))\n",
        "print('Hoeffding Tree accuracy: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 samples analyzed.\n",
            "Hoeffding Tree accuracy: 0.97565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDd9Z40DEF3H"
      },
      "source": [
        "### **KNN** on first data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7wd7IRK-nQI",
        "outputId": "3958d1ff-91e1-49ba-c558-50ee33efb9fa"
      },
      "source": [
        "#Setup KNN estimator and making prediction\n",
        "knn = KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40)\n",
        "# Keep track of sample count and correct prediction count\n",
        "n_samples = 0\n",
        "corrects = 0\n",
        "while n_samples < 25000:\n",
        "    X, y = stream.next_sample()\n",
        "    my_pred = knn.predict(X)\n",
        "    if y[0] == my_pred[0]:\n",
        "        corrects += 1\n",
        "    knn = knn.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "print('KNNClassifier usage example')\n",
        "print('{} samples analyzed.'.format(n_samples))\n",
        "print(\"KNNClassifier's performance: {}\".format(corrects/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNNClassifier usage example\n",
            "25000 samples analyzed.\n",
            "KNNClassifier's performance: 0.98704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqQV4es1EkJy"
      },
      "source": [
        "## **HT** on second data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is5TZgQgCHHG",
        "outputId": "05e8ee48-2268-4d7c-cce1-8e0bada1598a"
      },
      "source": [
        "# Setup Hoeffding Tree estimator and making prediction  - \n",
        "ht = HoeffdingTreeClassifier()\n",
        "# Setup variables to control loop and track performance\n",
        "n_samples2 = 0\n",
        "correct_cnt2 = 0\n",
        "max_samples2 = 20000\n",
        "\n",
        "# Train the estimator with the samples provided by the data stream\n",
        "while n_samples2 < max_samples2 and stream2.has_more_samples():\n",
        "    X2, y2 = stream2.next_sample()\n",
        "    y_pred2 = ht.predict(X2)\n",
        "    if y2[0] == y_pred2[0]:\n",
        "        correct_cnt2 += 1\n",
        "    ht = ht.partial_fit(X2, y2)\n",
        "    n_samples2 += 1\n",
        "\n",
        "print('{} samples analyzed.'.format(n_samples2))\n",
        "print('Hoeffding Tree accuracy: {}'.format(correct_cnt2 / n_samples2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 samples analyzed.\n",
            "Hoeffding Tree accuracy: 0.88095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu5uA4iEE1kq"
      },
      "source": [
        "## **KNN** on the second data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2syzeRJbEyZF",
        "outputId": "eb6d079f-30fd-45ec-cf43-8225c385f82b"
      },
      "source": [
        "#Setup KNN estimator and making prediction\n",
        "knn = KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40)\n",
        "# Keep track of sample count and correct prediction count\n",
        "n_samples = 0\n",
        "corrects = 0\n",
        "while n_samples < 25000:\n",
        "    X, y = stream.next_sample()\n",
        "    my_pred = knn.predict(X)\n",
        "    if y[0] == my_pred[0]:\n",
        "        corrects += 1\n",
        "    knn = knn.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "print('KNNClassifier usage example')\n",
        "print('{} samples analyzed.'.format(n_samples))\n",
        "print(\"KNNClassifier's performance: {}\".format(corrects/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNNClassifier usage example\n",
            "25000 samples analyzed.\n",
            "KNNClassifier's performance: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la5tdxhOIfJT"
      },
      "source": [
        "## **HT** on third data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg4eF7vPFtB9",
        "outputId": "65ec603f-fac4-4733-f9d5-7a36afa858b1"
      },
      "source": [
        "# Setup Hoeffding Tree estimator and making prediction  - \n",
        "ht = HoeffdingTreeClassifier()\n",
        "# Setup variables to control loop and track performance\n",
        "n_samples3 = 0\n",
        "correct_cnt3 = 0\n",
        "max_samples3 = 20000\n",
        "\n",
        "# Train the estimator with the samples provided by the data stream\n",
        "while n_samples3 < max_samples3 and stream3.has_more_samples():\n",
        "    X3, y3 = stream3.next_sample()\n",
        "    y_pred3 = ht.predict(X3)\n",
        "    if y3[0] == y_pred3[0]:\n",
        "        correct_cnt3 += 1\n",
        "    ht = ht.partial_fit(X3, y3)\n",
        "    n_samples3 += 1\n",
        "\n",
        "print('{} samples analyzed.'.format(n_samples3))\n",
        "print('Hoeffding Tree accuracy: {}'.format(correct_cnt3 / n_samples3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 samples analyzed.\n",
            "Hoeffding Tree accuracy: 0.6703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqdC5VZwJApK"
      },
      "source": [
        "## **KNN** on the third data stream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ag31c6I8mO",
        "outputId": "18e768c1-e34d-462e-d5d7-6d9b128fd712"
      },
      "source": [
        "#Setup KNN estimator and making prediction\n",
        "knn = KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40)\n",
        "# Keep track of sample count and correct prediction count\n",
        "n_samples3 = 0\n",
        "corrects3 = 0\n",
        "while n_samples3 < 25000:\n",
        "    X, y = stream3.next_sample()\n",
        "    my_pred = knn.predict(X)\n",
        "    if y[0] == my_pred[0]:\n",
        "        corrects3 += 1\n",
        "    knn = knn.partial_fit(X, y)\n",
        "    n_samples3 += 1\n",
        "\n",
        "print('KNNClassifier usage example')\n",
        "print('{} samples analyzed.'.format(n_samples3))\n",
        "print(\"KNNClassifier's performance: {}\".format(corrects3/n_samples3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNNClassifier usage example\n",
            "25000 samples analyzed.\n",
            "KNNClassifier's performance: 0.6446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCll1_SiNFhg"
      },
      "source": [
        "## **Bacth HT** with batch classification first dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABHRzC9wJWmF",
        "outputId": "02efd070-700c-4191-ca95-b95f43b17400"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=HoeffdingTreeClassifier())\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream.has_more_samples():\n",
        "    X, y = stream.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch classifier example\n",
            "20000 samples analyzed\n",
            "Performance: 0.94965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLnJH9oUQX6-"
      },
      "source": [
        "## **Batch HT** with batch classification second dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwB0ZsvgNih_",
        "outputId": "153121b4-46dc-420c-d6a4-2ee3e6a92d00"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=HoeffdingTreeClassifier())\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream2.has_more_samples():\n",
        "    X, y = stream2.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch Hoeffding classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Hoeffding classifier example\n",
            "20000 samples analyzed\n",
            "Performance: 0.8837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GcXU9ulSZGO"
      },
      "source": [
        "## **Batch HT** with batch classification third dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr5jLHwPRAnu",
        "outputId": "ecf180c9-7c07-4a40-a9a9-85b5310b7de9"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=HoeffdingTreeClassifier())\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream3.has_more_samples():\n",
        "    X, y = stream3.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch Hoeffding classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Hoeffding classifier example\n",
            "20000 samples analyzed\n",
            "Performance: 0.64525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NU1nlZRSoRx"
      },
      "source": [
        "## **Batch KNN** classifier on first dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvnRLO0qSg1Z",
        "outputId": "d4f842b3-478e-4a59-a972-0ccf5123fb1e"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40))\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream.has_more_samples():\n",
        "    X, y = stream.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch KNN classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch KNN classifier example\n",
            "20000 samples analyzed\n",
            "Performance: 0.9704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU3RXnS4Wor6"
      },
      "source": [
        "## **Batch KNN** classifier on second dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "5i577DS_TVhV",
        "outputId": "5f3364bf-b031-497f-8d81-ac5d9034654c"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40))\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream2.has_more_samples():\n",
        "    X, y = stream2.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch KNN classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-37416a4fde74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstream2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_more_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_incremental_cfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultiflow/meta/batch_incremental.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \"\"\"\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Suppose a threshold of 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvotes\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultiflow/meta/batch_incremental.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# Add vote (normalized by number of models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvotes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvotes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultiflow/lazy/knn_classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultiflow/lazy/knn_classifier.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    175\u001b[0m                                         np.unique(self.data_window.targets_buffer.astype(np.int))))\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mnew_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultiflow/lazy/base_neighbors.py\u001b[0m in \u001b[0;36m_get_neighbors\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         dist, idx = tree.query(X=X,\n\u001b[0;32m---> 28\u001b[0;31m                                k=self.n_neighbors)\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" by %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mestimator_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \"\"\"\n\u001b[0;32m-> 1219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dm2nY2vW9xk"
      },
      "source": [
        "## **Batch KNN** classifier on third dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeI1-jJWW5Wx",
        "outputId": "73fd9da5-7195-4811-f405-12d96c1149f4"
      },
      "source": [
        "# Pre-training the classifier with 200 samples\n",
        "X, y = stream.next_sample(200)\n",
        "batch_incremental_cfier = BatchIncrementalClassifier(base_estimator=KNNClassifier(n_neighbors=8, max_window_size=20000, leaf_size=40))\n",
        "batch_incremental_cfier.partial_fit(X, y)\n",
        "\n",
        "# Preparing the processing of 5000 samples and correct prediction count\n",
        "n_samples = 0\n",
        "correct_cnt = 0\n",
        "while n_samples < 20000 and stream3.has_more_samples():\n",
        "    X, y = stream3.next_sample()\n",
        "    y_pred = batch_incremental_cfier.predict(X)\n",
        "    if y[0] == y_pred[0]:\n",
        "        correct_cnt += 1\n",
        "    batch_incremental_cfier.partial_fit(X, y)\n",
        "    n_samples += 1\n",
        "\n",
        "# Display results\n",
        "print('Batch KNN classifier example')\n",
        "print('{} samples analyzed'.format(n_samples))\n",
        "print('Performance: {}'.format(correct_cnt / n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Incremental ensemble classifier example\n",
            "20000 samples analyzed\n",
            "Performance: 0.6573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JySSEy40YiBN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}